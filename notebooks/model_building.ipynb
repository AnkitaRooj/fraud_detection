{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2128a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import IsolationForest, GradientBoostingClassifier\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score, \n",
    "                           precision_score, recall_score, f1_score, accuracy_score)\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e977b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('processeddataset/final_feature_paySim.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6283b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13470b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012e486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59527c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa0fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['isFraud'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b7f107",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud = df[df['isFraud']==1]\n",
    "non_fraud = df[df['isFraud']==0].sample(n=fraud.shape[0], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45266908",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat([fraud, non_fraud]).reset_index(drop=True)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dfb604",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dbf447",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    "'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest',\n",
    "'hour', 'is_weekend', 'high_risk_hour', 'high_risk_type', 'large_amount_flag',\n",
    "'zero_balance_orig', 'zero_balance_dest', 'balance_ratio_orig', 'balance_ratio_dest',\n",
    "'cust_avg_amt', 'cust_std_amt', 'cust_txn_count'\n",
    "]\n",
    "X = df[feature_columns]\n",
    "y = df['isFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f68d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original class distribution:\", Counter(y))\n",
    "print(f\"Fraud rate: {y.mean():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12606597",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4905f2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be5486e",
   "metadata": {},
   "source": [
    "* On Apply ROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03148128",
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train) # type: ignore\n",
    "y_train_ros.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766e9d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(y_train_ros.value_counts())  # type: ignore\n",
    "plt.title(\"Fraud(1) Vs Non Fraud(0) data distribution after ROS\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41853df",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be26e8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"Anomaly_Detection_Models_ROS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8854f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred, y_scores, model_name):\n",
    "\n",
    "    # Basic metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_scores)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # Business metrics\n",
    "    false_positive_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    false_negative_rate = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "    true_positive_rate = recall  # Same as recall\n",
    "    \n",
    "    # Classification report\n",
    "    cr = classification_report(y_true, y_pred, output_dict=True)\n",
    "    \n",
    "    results = {\n",
    "        'model_name': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'confusion_matrix': cm,\n",
    "        'false_positive_rate': false_positive_rate,\n",
    "        'false_negative_rate': false_negative_rate,\n",
    "        'true_positive_rate': true_positive_rate,\n",
    "        'true_positives': tp,\n",
    "        'false_positives': fp,\n",
    "        'true_negatives': tn,\n",
    "        'false_negatives': fn,\n",
    "        'classification_report': cr,\n",
    "        'predictions': y_pred,\n",
    "        'scores': y_scores\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(f\"False Positive Rate: {false_positive_rate:.4f}\")\n",
    "    print(f\"False Negative Rate: {false_negative_rate:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc60afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_model_to_mlflow(model, metrics, model_name, params):\n",
    "\n",
    "    # Log parameters\n",
    "    for param, value in params.items():\n",
    "        mlflow.log_param(param, value)\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", metrics['accuracy'])\n",
    "    mlflow.log_metric(\"precision\", metrics['precision'])\n",
    "    mlflow.log_metric(\"recall\", metrics['recall'])\n",
    "    mlflow.log_metric(\"f1_score\", metrics['f1_score'])\n",
    "    mlflow.log_metric(\"roc_auc\", metrics['roc_auc'])\n",
    "    mlflow.log_metric(\"false_positive_rate\", metrics['false_positive_rate'])\n",
    "    mlflow.log_metric(\"false_negative_rate\", metrics['false_negative_rate'])\n",
    "    mlflow.log_metric(\"true_positive_rate\", metrics['true_positive_rate'])\n",
    "    mlflow.log_metric(\"true_positives\", metrics['true_positives'])\n",
    "    mlflow.log_metric(\"false_positives\", metrics['false_positives'])\n",
    "    mlflow.log_metric(\"true_negatives\", metrics['true_negatives'])\n",
    "    mlflow.log_metric(\"false_negatives\", metrics['false_negatives'])\n",
    "    \n",
    "    # Log classification report as JSON\n",
    "    mlflow.log_dict(metrics['classification_report'], \"classification_report.json\")\n",
    "    \n",
    "    # Log confusion matrix as plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(metrics['confusion_matrix'], annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    mlflow.log_figure(plt.gcf(), f\"confusion_matrix_{model_name.replace(' ', '_')}.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(model, name = f\"model_{model_name.replace(' ', '_')}\",\n",
    "                             input_example=X_train.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b937c15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "results = {}\n",
    "with mlflow.start_run(run_name=\"Isolation_Forest\"):\n",
    "        # Train Isolation Forest\n",
    "        iso_forest = IsolationForest(\n",
    "            n_estimators=100,\n",
    "            contamination=0.01,  # Approximate fraud rate\n",
    "            random_state=42,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        iso_forest.fit(X_train)\n",
    "        \n",
    "        # Predict on test set\n",
    "        y_pred_iso = iso_forest.predict(X_test)\n",
    "        y_scores_iso = iso_forest.decision_function(X_test)\n",
    "        \n",
    "        # Convert predictions (1 = normal, -1 = anomaly) to (0 = normal, 1 = anomaly)\n",
    "        y_pred_iso_binary = (y_pred_iso == -1).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        results['Isolation_Forest'] = calculate_metrics(\n",
    "            y_test, y_pred_iso_binary, y_scores_iso, \"Isolation Forest\"\n",
    "        )\n",
    "        \n",
    "        # Log to MLflow\n",
    "        log_model_to_mlflow(\n",
    "            iso_forest, \n",
    "            results['Isolation_Forest'], \n",
    "            \"Isolation Forest\",\n",
    "            {\n",
    "                'n_estimators': 100,\n",
    "                'contamination': 0.01,\n",
    "                'random_state': 42\n",
    "            }\n",
    "        )\n",
    "        os.makedirs('models', exist_ok=True)\n",
    "        joblib.dump(iso_forest, 'models/iso_forest_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d24a6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "\n",
    "# mlflow.set_experiment(\"Isolation_Forest_Hyperparameter_Tuning\")\n",
    "\n",
    "# def hyperparameter_tuning(X_train, X_test, y_test):\n",
    "#     # Define parameter grid\n",
    "#     param_dist = {\n",
    "#         'n_estimators': randint(50, 300),\n",
    "#         'contamination': uniform(0.001, 0.1),  # 0.1% to 10%\n",
    "#         'max_samples': uniform(0.5, 0.5),  # 0.5 to 1.0\n",
    "#         'max_features': uniform(0.5, 0.5)   # 0.5 to 1.0\n",
    "#     }\n",
    "    \n",
    "#     results = {}\n",
    "#     best_score = -1\n",
    "#     best_params = None\n",
    "#     best_model = None\n",
    "    \n",
    "#     # Create all parameter combinations\n",
    "#     grid = ParameterGrid(param_grid)\n",
    "#     print(f\"Total combinations to try: {len(grid)}\")\n",
    "    \n",
    "#     for i, params in enumerate(grid):\n",
    "#         with mlflow.start_run(run_name=f\"IF_Tuning_{i}\", nested=True):\n",
    "#             # Log parameters\n",
    "#             mlflow.log_params(params)\n",
    "            \n",
    "#             # Train Isolation Forest with current parameters\n",
    "#             iso_forest = IsolationForest(\n",
    "#                 n_estimators=params['n_estimators'],\n",
    "#                 contamination=params['contamination'],\n",
    "#                 max_samples=params['max_samples'],\n",
    "#                 random_state=42,\n",
    "#                 verbose=0\n",
    "#             )\n",
    "            \n",
    "#             iso_forest.fit(X_train)\n",
    "            \n",
    "#             # Predict on test set\n",
    "#             y_pred_iso = iso_forest.predict(X_test)\n",
    "#             y_scores_iso = iso_forest.decision_function(X_test)\n",
    "            \n",
    "#             # Convert predictions (1 = normal, -1 = anomaly) to (0 = normal, 1 = anomaly)\n",
    "#             y_pred_iso_binary = (y_pred_iso == -1).astype(int)\n",
    "            \n",
    "#             # Calculate metrics\n",
    "#             current_results = calculate_metrics(y_test, y_pred_iso_binary, y_scores_iso, \"Isolation Forest\")\n",
    "            \n",
    "#             # Log metrics to MLflow\n",
    "#             for metric_name, metric_value in current_results.items():\n",
    "#                 if isinstance(metric_value, (int, float)):\n",
    "#                     mlflow.log_metric(metric_name, metric_value)\n",
    "            \n",
    "#             # Track best model\n",
    "#             f1_score = current_results.get('F1-Score', 0)\n",
    "#             if f1_score > best_score:\n",
    "#                 best_score = f1_score\n",
    "#                 best_params = params\n",
    "#                 best_model = iso_forest\n",
    "            \n",
    "#             # Log model\n",
    "#             mlflow.sklearn.log_model(iso_forest, name = \"ISOLATION_FOREST_model\")\n",
    "            \n",
    "#             # Store results\n",
    "#             results[f\"run_{i}\"] = {\n",
    "#                 'params': params,\n",
    "#                 'metrics': current_results\n",
    "#             }\n",
    "    \n",
    "#     return best_model, best_params, best_score, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb3b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "mlflow.set_experiment(\"Isolation_Forest_Hyperparameter_Tuning_USing_RandomizedSearchCV\")\n",
    "def randomized_search_tuning(X_train, X_test, y_test, n_iter=5):\n",
    "    # Define parameter distribution\n",
    "    param_dist = {\n",
    "        'n_estimators': randint(50, 300),\n",
    "        'contamination': uniform(0.001, 0.1),  # 0.1% to 10%\n",
    "        'max_samples': uniform(0.5, 0.5),  # 0.5 to 1.0\n",
    "        'max_features': uniform(0.5, 0.5)   # 0.5 to 1.0\n",
    "    }\n",
    "    \n",
    "    # Create Isolation Forest model\n",
    "    iso_forest = IsolationForest(random_state=42, verbose=0)\n",
    "    \n",
    "    # Custom scorer for anomaly detection\n",
    "    from sklearn.metrics import make_scorer, f1_score\n",
    "    scorer = make_scorer(f1_score)\n",
    "    \n",
    "    with mlflow.start_run(run_name=\"RandomizedSearch_IF\"):\n",
    "        # Perform randomized search\n",
    "        random_search = RandomizedSearchCV(\n",
    "            estimator=iso_forest,\n",
    "            param_distributions=param_dist,\n",
    "            n_iter=n_iter,\n",
    "            scoring=scorer,\n",
    "            cv=3,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Fit the model\n",
    "        random_search.fit(X_train)\n",
    "        \n",
    "        # Log best parameters\n",
    "        mlflow.log_params(random_search.best_params_)\n",
    "        \n",
    "        # Get best model\n",
    "        best_model = random_search.best_estimator_\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        y_pred = best_model.predict(X_test) # type: ignore\n",
    "        y_scores = best_model.decision_function(X_test) # type: ignore\n",
    "        y_pred_binary = (y_pred == -1).astype(int)\n",
    "        \n",
    "        # Calculate and log metrics\n",
    "        test_results = calculate_metrics(y_test, y_pred_binary, y_scores, \"Best Isolation Forest\")\n",
    "        for metric_name, metric_value in test_results.items():\n",
    "            if isinstance(metric_value, (int, float)):\n",
    "                mlflow.log_metric(f\"test_{metric_name}\", metric_value)\n",
    "        \n",
    "        # Log the best model\n",
    "        mlflow.sklearn.log_model(best_model, \"best_model\") # type: ignore\n",
    "        \n",
    "        # Log search results\n",
    "        mlflow.log_metric(\"best_cv_score\", random_search.best_score_)\n",
    "        \n",
    "        return best_model, random_search.best_params_, test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92fa0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, best_params_, test_results = randomized_search_tuning(X_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47786406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "results = {}\n",
    "with mlflow.start_run(run_name=\"Gradient_Boosting_ROS\"):\n",
    "        # Create pipeline with ROS and Gradient Boosting\n",
    "        gb_pipeline = Pipeline([\n",
    "            ('ros', RandomOverSampler(random_state=42)),\n",
    "            ('classifier', lgb.LGBMClassifier(\n",
    "                        objective='binary',               # Use 'binary' for 0/1 classification\n",
    "                        metric='auc',                     # Use Area Under the Curve for evaluation\n",
    "                        n_estimators=1000,\n",
    "                        learning_rate=0.05,\n",
    "                        num_leaves=31,\n",
    "                        random_state=42,\n",
    "                        n_jobs=-1,\n",
    "                        # Crucial for Imbalance: Use is_unbalance to let LGBM handle it internally\n",
    "                        # Alternatively, you can use scale_pos_weight\n",
    "                        is_unbalance=True \n",
    "                    )\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        gb_pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on test set\n",
    "        y_pred_gb = gb_pipeline.predict(X_test)\n",
    "        y_scores_gb = gb_pipeline.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        results['LightGBM_ROS'] = calculate_metrics(\n",
    "            y_test, y_pred_gb, y_scores_gb, 'LightGBM with ROS'\n",
    "        )\n",
    "        \n",
    "        # Log to MLflow\n",
    "        log_model_to_mlflow(\n",
    "            gb_pipeline, \n",
    "            results['LightGBM_ROS'], \n",
    "            'LightGBM with ROS',\n",
    "            {\n",
    "                'n_estimators': 1000,\n",
    "                'learning_rate': 0.1,\n",
    "                'num_leaves':31\n",
    "                ,\n",
    "                'ros_applied': True\n",
    "            }\n",
    "        )\n",
    "        os.makedirs('models', exist_ok=True)\n",
    "        joblib.dump(iso_forest, 'models/lightgbm_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vfraud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
